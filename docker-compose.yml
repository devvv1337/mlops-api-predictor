# ./docker-compose.yml

version: '3.8'

services:
  trainer:
    build: .
    container_name: mlops_trainer
    entrypoint: ["python", "model.py"]
    depends_on:
      mlflow:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_DEFAULT_REGION
      - DOCKER_CONTAINER=true
    volumes:
      - ./app:/app
      - ./models:/models
      - ./data:/app/data
      - ./params.yaml:/app/params.yaml
    networks:
      - mlops_network

  api:
    build: .
    container_name: mlops_api
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_DEFAULT_REGION
      - DOCKER_CONTAINER=true  
    depends_on:
      - prometheus
      - trainer
      - mlflow  # Assurez-vous que l'API dépend également de MLflow
    volumes:
      - ./data:/app/data  # Montez le répertoire data si nécessaire
    networks:
      - mlops_network

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./dashboards/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./dashboards/alert.rules.yml:/etc/prometheus/alert.rules.yml
    ports:
      - "9090:9090"
    networks:
      - mlops_network

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./dashboards/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    networks:
      - mlops_network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - ./dashboards/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./dashboards/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - mlops_network

  mlflow:
    image: python:3.9-slim
    container_name: mlflow
    working_dir: /mlflow
    command: >
      sh -c "apt-get update && apt-get install -y curl && pip install mlflow==2.2.1 &&
      mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ${MLFLOW_ARTIFACT_ROOT} --host 0.0.0.0 --port 5000"
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
      - AWS_DEFAULT_REGION
      - MLFLOW_ARTIFACT_ROOT=s3://${AWS_S3_BUCKET}/mlartifacts
    env_file:
      - .env
    volumes:
      - ./mlflow_data:/mlflow
    ports:
      - "5000:5000"
    networks:
      - mlops_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://mlflow:5000/"]
      interval: 40s
      timeout: 10s
      retries: 10

  ngrok:
    image: wernight/ngrok
    container_name: ngrok
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
      - NGROK_OPTS=--region=us
      - NGROK_PORT=api:8000  # Modification ici
    depends_on:
      - api
    ports:
      - "4040:4040"  # Port pour l'interface web de ngrok
    networks:
      - mlops_network

networks:
  mlops_network:
    driver: bridge
